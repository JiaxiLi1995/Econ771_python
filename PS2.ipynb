{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f769895",
   "metadata": {},
   "source": [
    "# Econ 711 - Problem Set 2\n",
    "Coding Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9fa5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47286a2c",
   "metadata": {},
   "source": [
    "## Exercise II\n",
    "\n",
    "<b>\n",
    "\n",
    "Hayashi, Empirical exercise (a)-(h), p. 76-81\n",
    "\n",
    "<br>\n",
    "\n",
    "<blockquote>\n",
    "\n",
    "Read Marc Nerlove, “Returns to Scale in Electricity Supply” (except paragraphs of equations (6)–(9), the part of section 2 from p. 184 on, and Appendix A and C) before doing this exercise. For 145 electric utility companies in 1955, the file NERLOVE.ASC has data on the following:\n",
    "\n",
    "Column 1: total costs (call it $TC$) in millions of dollars\n",
    "\n",
    "Column 2: output ($Q$) in billions of kilowatt hours\n",
    "\n",
    "Column 3: price of labor ($PL$)\n",
    "\n",
    "Column 4: price of fuels ($PF$)\n",
    "\n",
    "Column 5: price of capital ($PK$).\n",
    "\n",
    "They are from the data appendix of his article. There are 145 observations, and the observations are ordered in size, observation 1 being the smallest company and observation 145 the largest. Using the data transformation facilities of your computer software, generate for each of the 145 firms the variables required for estimation. To estimate (1.7.4), for example, you need to generate $\\log(TC)$, a constant, $\\log(Q)$, $\\log(PL)$, $\\log(PK)$, and $\\log(PF)$, for each of the 145 firms.\n",
    "\n",
    "</blockquote>\n",
    "\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a6a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I found the dta version data here: http://fmwww.bc.edu/ec-p/data/Hayashi/\n",
    "# One can also find the src or excel data from his website: http://fhayashi.fc2web.com/datasets.htm\n",
    "ps2_data = pd.read_stata(\"http://fmwww.bc.edu/ec-p/data/Hayashi/nerlove63.dta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1a870d",
   "metadata": {},
   "source": [
    "**(a) (Data question) Does Nerlove’s construction of the price of capital conform to the definition of the user cost of capital? Hint: Read Nerlove’s Appendix B.4.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c313ceff-2568-4de2-8a7f-85297011a02f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8def5f01",
   "metadata": {},
   "source": [
    "**(b) Estimate the unrestricted model (1.7.4) by OLS. Can you replicate the estimates in the text?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3314fd22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb8490b5",
   "metadata": {},
   "source": [
    "**(c) (Restricted least squares) Estimate the restricted model (1.7.6) by OLS. To do this, you need to generate a new set of variables for each of the 145 firms. For example, the dependent variable is $\\log(TC/PF)$, not $\\log(TC)$. Can you replicate the estimates in the text? Can you replicate Nerlove’s results? Nerlove’s estimate of $\\beta_2$ for example, is 0.721 with a standard error of 0.0174 (the standard error in his paper is 0.175, but it is probably a typographical error). Where in Nerlove’s paper can you find this estimate? What about the other coefficients? (Warning: You will not be able to replicate Nerlove’s results precisely. One reason is that he used common rather than natural logarithms; however, this should affect only the estimated intercept term. The other reason: the data set used for his results is a corrected version of the data set published with his article.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33824ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e714a9c-8528-4d99-867a-cddb5e7e626c",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "\n",
    "<b>\n",
    "\n",
    "As mentioned in the text, the plot of residuals suggests a nonlinear relationship between $\\log(TC)$ and $\\log(Q)$. Nerlove hypothesized that estimated returns to scale varied with the level of output. Following Nerlove, divide the sample of 145 firms into five subsamples or groups, each having 29 firms. (Recall that since the data are ordered by level of output, the first 29 observations will have the smallest output levels, whereas the last 29 observations will have the largest output levels.) Consider the following three generalizations of the model (1.7.6):\n",
    "\n",
    "Model 1: Both the coefficients ($\\beta$’s) and the error variance in (1.7.6) differ across groups.\n",
    "\n",
    "Model 2: The coefficients are different, but the error variance is the same across groups.\n",
    "\n",
    "Model 3: While each group has common coefficients for $\\beta_3$ and $\\beta_4$ (price elasticities) and common error variance, it has a different intercept term and a different $\\beta_2$. Model 3 is what Nerlove called the hypothesis of neutral variations in returns to scale.\n",
    "\n",
    "<br>\n",
    "\n",
    "For Model 1, the coefficients and error variances specific to groups can be estimated from\n",
    "$$y^{(j)} = X^{(j)} \\beta^{(j)} + \\epsilon^{(j)} \\ \\ \\ \\ \\ \\ \\ (j = 1, \\dots, 5)$$\n",
    "\n",
    "where $y^{(j)} (29 \\times 1)$ is the vector of the values of the dependent variable for group $j$ , $X^{(j)} (29 \\times 4)$ is the matrix of the values of the four regressors for group $j$, $\\beta^{(j)} (4 \\times 1)$ is the coefficient vector for group $j$, and $\\epsilon^{(j)} (29 \\times 1)$ is the error vector. The second column of $X^{(5)}$, for example, is $\\log(Q)$ for $i = 117, \\dots, 145$. Model 1 assumes conditional homoskedasticity $E(\\epsilon^{(j)} \\epsilon^{(j)'} | X^{(j)}) = \\sigma_j^2 I_{29}$ within (but not necessarily across) groups.\n",
    "\n",
    "</b>\n",
    "\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc15aa2a-c22f-4542-b315-68640871d6b4",
   "metadata": {},
   "source": [
    "**(d) Estimate Model 1 by OLS. How well can you replicate Nerlove’s reported results? On the basis of your estimates of $\\beta_2$, compute the point estimates of returns to scale in each of the five groups. What is the general pattern of estimated scale economies as the level of output increases? What is the general pattern of the estimated error variance as output increases?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac3efc3-8ba2-4ca0-9d02-493aad35c05c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d5bab24-3a52-40c7-8d17-fabbfcd06f9d",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "\n",
    "<b>\n",
    "\n",
    "Model 2 assumes for Model 1 that $\\sigma_j^2 = \\sigma^2$ for all $j$. This equivariance restriction can be incorporated by stacking vectors and matrices as follows:\n",
    "$$y = X\\beta + \\epsilon,$$\n",
    "\n",
    "where\n",
    "$$\\underset{(145 \\times 1)}{y} = \\begin{bmatrix} y^{(1)} \\\\ \\vdots \\\\ y^{(5)} \\end{bmatrix}, \\underset{(145 \\times 20)}{X} = \\begin{bmatrix} X^{(1)} & & \\\\ & \\ddots & \\\\ & & X^{(5)} \\end{bmatrix}, \\underset{(145 \\times 1)}{\\epsilon} = \\begin{bmatrix} \\epsilon^{(1)} \\\\ \\vdots \\\\ \\epsilon^{(5)} \\end{bmatrix}. \\ \\ \\ \\ (*)$$\n",
    "\n",
    "In particular, $X$ is now a block-diagonal matrix. The equivariance restriction can be expressed as $E(\\epsilon \\epsilon' | X) = \\sigma^2 I_{145}$. There are now 20 variables derived from the original four regressors. The 145 dimensional vector corresponding to the second variable, for example, has $\\log(Q_1), \\dots, \\log(Q_{29})$ as the first 29 elements and zeros elsewhere. The vector corresponding to the 6th variable, which represents log output for the second group of firms, has $\\log(Q_{30}), \\dots, \\log(Q_{58})$ for the 30th through 58th elements and zeros elsewhere, and so on.\n",
    "\n",
    "The stacking operation needed to form the $y$ and $X$ in (*) can be done easily if your computer software is matrix-based. Otherwise, you trick your software into accomplishing the same thing by the use of dummy variables. Define the $j$-th dummy variable as\n",
    "\n",
    "\\begin{align*}\n",
    "D_{j,i} = \n",
    "\\begin{cases} \n",
    "1 & \\text{if firm $i$ belongs to the $j$-th group,} \\\\\n",
    "0 & \\text{otherwise,}\n",
    "\\end{cases} & & & & i = \\{1; \\dots ; 145\\}.\n",
    "\\end{align*}\n",
    "\n",
    "Then the second regressor is $D_{1i} * \\log(Q_i)$. The 6th variable is $D_{2i} * \\log(Q_i)$, and so forth.\n",
    "\n",
    "</b>\n",
    "\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deab5b13-2579-49bd-9d3d-115fb24ee34a",
   "metadata": {},
   "source": [
    "<b>\n",
    "\n",
    "(e) Estimate Model 2 by OLS. Verify that the OLS coefficient estimates here are the same as those in (d). Also verify that\n",
    "$$\\sum_{j=1}^5 SSR_j = SSR,$$\n",
    "\n",
    "where $SSR_j$ is the $SSR$ from the $j$-th group in your estimation of Model 1 in (d) and $SSR$ is the $SSR$ from Model 2. This agreement is not by accident, i.e., not specific to the present data set. Prove that this agreement for the coefficients and the $SSR$ holds in general, temporarily assuming just two groups without loss of generality. Hint: First show that the coefficient estimate is the same between Model 1 and Model 2. Use formulas (A.4), (A.5), and (A.9) of Appendix A.\n",
    "\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10be5f8-340b-4275-8de1-76f4250b9576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d129debf-1c82-4689-bb4c-6841854ffed6",
   "metadata": {},
   "source": [
    "**(f) (Chow test) Model 2 is more general than Model (1.7.6) because the coefficients can differ across groups. Test the null hypothesis that the coefficients are the same across groups. How many equations (restrictions) are in the null hypothesis? This test is sometimes called the Chow test for structural change. Calculate the p-value of the F-ratio. Hint: This is a linear hypothesis about the coefficients of Model 2. So take Model 2 to be the maintained hypothesis and (1.7.6) to be the restricted model. Use the formula (1.4.11) for the F-ratio.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45f4cee-a04e-42e8-bf7c-b2d876fa0c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3455545-5eda-4705-9adf-02a24f2ed694",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "\n",
    "<b>\n",
    "\n",
    "The restriction in Model 3 that the price elasticities are the same across firm groups can be imposed on Model 2 by applying the dummy variable transformation only to the constant and log output. Thus, there are $12(=2 \\times 5 + 2)$ variables in $X$. Now $X$ looks like\n",
    "$$X = \\begin{bmatrix} 1 & \\log(Q_1) & & 0 & 0 & \\log(PL_1/PF_1) & \\log(PK_1/PF_1) \\\\\n",
    "\\vdots & \\vdots & & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "1 & \\log(Q_{29}) & & 0 & 0 & \\log(PL_{29}/PF_{29}) & \\log(PK_{29}/PF_{29}) \\\\\n",
    "& & \\ddots & & & \\vdots & \\vdots \\\\\n",
    "0 & 0 & & 1 & \\log(Q_{117}) & \\log(PL_{117}/PF_{117}) & \\log(PK_{117}/PF_{117}) \\\\\n",
    "\\vdots & \\vdots & & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "0 & 0 & & 1 & \\log(Q_{145}) & \\log(PL_{145}/PF_{145}) & \\log(PK_{145}/PF_{145}) \\\\\n",
    "\\end{bmatrix} (**)$$\n",
    "\n",
    "</b>\n",
    "\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df3641e-2617-4e80-8c35-0488bbd30393",
   "metadata": {},
   "source": [
    "**(g) Estimate Model 3. The model is a special case of Model 2, with the hypothesis that the two price elasticities are the same across the five groups. Test the hypothesis at a significance level of 5 percent, assuming normality. (Note: Nerlove’s F-ratio on p. 183 is wrong.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b03e08-f8e4-4b96-8f23-ed1acff0e2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60e37844-ef19-47fe-9006-bc19aa92513f",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "\n",
    "<b>\n",
    "\n",
    "As has become clear from the plot of residuals in Figure 1.7, the conditional second moment $E(\\epsilon_i^2 | X)$ is likely to depend on log output, which is a violation of the conditional homoskedasticity assumption. This time we do not attempt to test conditional homoskedasticity, because to do so requires large sample theory and is postponed until the next chapter. Instead, we pretend to know the form of the function linking the conditional second moment to log output. The function, specified below, implies that the conditional second moment varies continuously with output, contrary to the three models we have considered above. Also contrary to those models, we assume that the degree of returns to scale varies continuously with output by including the square of log output. Model 4 is\n",
    "\n",
    "Model 4:\n",
    "$$log(\\frac{TC_i}{p_{i3}}) = \\beta_1 + \\beta_2 \\log(Q_i) + \\beta_3 [\\log(Q_i)]^2$$\n",
    "$$+ \\beta_4 \\log(\\frac{p_{i1}}{p_{i3}}) + \\beta_5 \\log(\\frac{p_{i2}}{p_{i3}}) + \\epsilon_i$$\n",
    "$$E(\\epsilon_i^2 | X) = \\sigma^2 \\cdot (0.0565 + \\frac{2.1377}{Q_i}) \\ \\ \\ (i = 1,2,\\dots,145)$$\n",
    "for some unknown $\\sigma^2$.\n",
    "\n",
    "</b>\n",
    "\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1eddc4-02e8-4a27-9129-66c7af76fca4",
   "metadata": {},
   "source": [
    "**(h) Estimate Model 4 by weighted least squares on the whole sample of 145 firms. (Be careful about the treatment of the intercept; in the equation after weighting, none of the regressors is a constant.) Plot the residuals. Is there still evidence for conditional homoskedasticity or further nonlinearities?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a2f823-7090-49a9-b02b-bbe003820dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
