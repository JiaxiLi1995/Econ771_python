{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f769895",
   "metadata": {},
   "source": [
    "# Econ 711 - Problem Set 6\n",
    "Coding Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaa9008-e406-4504-90b3-df1e2afc4af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9fa5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for the timing of the code run time, please do not modify\n",
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ebd75d-21df-408f-9605-ea9ec0363c72",
   "metadata": {},
   "source": [
    "## Exercise I\n",
    "\n",
    "<blockquote>\n",
    "\n",
    "<b>\n",
    "\n",
    "This exercise is a continuation of the Exercise I from the Problem Set 3. Consider the DGP with heteroskedastic regression errors as in part 2.\n",
    "\n",
    "</b>\n",
    "\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1a870d",
   "metadata": {},
   "source": [
    "<b>\n",
    "\n",
    "1. Explore the distribution of the OLS estimator under heteroskedasticity using Eicker-White standard errors (follow steps (a)-(e)). Next, increase the sample to n = 100 observations and repeat everything. Conclude.\n",
    "\n",
    "Reminder of PS3 part 2:\n",
    "\n",
    "Now we introduce heteroskedasticity as follows\n",
    "$$Y = \\beta_1 + \\beta_2 X_2 + \\beta_3 X_3 + \\tilde{\\epsilon},$$\n",
    "\n",
    "with coefficients set to $\\beta_1 = 1$, $\\beta_2 = 2$, $\\beta_3 = 3$ and the data generated as $X_2 \\sim N(0, 1)$, $X_3 \\sim N(0, 1)$, $\\epsilon \\sim N(0, 1)$ with $X_2 \\coprod X_3 \\coprod \\epsilon$, where $\\tilde{\\epsilon} = \\epsilon(X_2 + X_3)$.\n",
    "\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eb2ed5-8d02-44cf-b6dd-e2bfb5497839",
   "metadata": {},
   "source": [
    "**(a) For each $m = 1, \\dots, M$, compute the OLS estimator $\\hat{\\beta}_m = (\\hat{\\beta}_{1m}, \\hat{\\beta}_{2m}, \\hat{\\beta}_{3m})^T$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c313ceff-2568-4de2-8a7f-85297011a02f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d53def2f-c636-4811-8d4a-6f3d5c749753",
   "metadata": {},
   "source": [
    "**(b) Plot three histograms of standardized estimators assuming that $\\sigma^2$ is known. Plot the probability density function of $N(0, 1)$ at each histogram.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4768af13-cf68-44be-834a-7d7cb164d718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83f24b04-5de5-42db-a8d6-1c8b18ac756f",
   "metadata": {},
   "source": [
    "**(c) Replace $\\sigma^2$ by its unbiased estimator $\\hat{\\sigma}^2$ and plot histograms of $\\frac{\\hat{\\beta}_{km} - \\beta_{km}}{\\sqrt{\\hat{\\sigma}^2 (X^T X)^{-1}}}$ with the probability function of $N(0, 1)$. What is the distribution of the standardized estimators now?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db233dd-ecc3-4ce7-a1f3-4766a34b2971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22635ad7-846c-4782-9838-5e76dc8ab209",
   "metadata": {},
   "source": [
    "**(d) Fix significance level at 5%. Compute the empirical size of the t-test – the fraction of times you reject the null-hypothesis when it is actually correct.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96881a78-cda6-4270-814e-c9337302a00c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a68c641-99ec-41ab-97b4-6b15a641d255",
   "metadata": {},
   "source": [
    "**(e) Compute the empirical power of the t-test for the significance test ($H_0 : \\beta_k = 0$) – the fraction of times you reject the null-hypothesis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e32bb-f833-4109-baf0-34e5956d7cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6f30fee-c4a9-4c79-a59d-e58e5aa6df1d",
   "metadata": {},
   "source": [
    "**(f) Conclude.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9016a714-34eb-436e-ad50-4612cf2b9680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb8490b5",
   "metadata": {},
   "source": [
    "<b>\n",
    "\n",
    "2. Now we fix the sample size at n = 30 observations. Explore empirical size and power properties (You don’t need to plot histograms for this part.) of the t-test using the following wild bootstrap procedure (you have to do the bootstrap for each Monte Carlo replication. You can try parallel computing.):\n",
    "\n",
    "<ol>\n",
    "\n",
    "<li> For each MC replication, $m = 1, \\dots, M$, simulate the data. Estimate the linear regression coefficient $\\hat{\\beta}$ and compute residuals $\\hat{u}$; </li>\n",
    "\n",
    "<li> Create $B$ bootstrap samples using the wild bootstrap\n",
    "$$Y_i^* = X_i^T \\hat{\\beta} + \\eta_i \\hat{u}_i, \\ \\ \\ \\ i = 1, \\dots, n,$$ </li>\n",
    "\n",
    "where $\\eta_i$ are i.i.d. draws from the two-point distribution introduced in class (Please check my pdf notes in order to make sure that the you draw from the correct two-point distribution.). </li>\n",
    "\n",
    "<li> For each bootstrap sample, estimate the linear regression coefficients $(\\hat{\\beta})_{b=1}^B$ and Eicker-White standard errors $\\{se(\\hat{\\beta}_{k,b}^*) = \\sqrt{\\hat{V}_{k,b}^*/n}: k = 1, 2, 3, b = 1, \\dots, B\\}$, where $\\hat{V}_{k,b}^*$ is the kth diagonal element of the Eicker-White covariance matrix estimator. Compute absolute values of t-statistics\n",
    "$$T_{n,k}^b = |\\frac{\\hat{\\beta}_{k,b}^* - \\hat{\\beta}}{se(\\hat{\\beta}_{k,b}^*)}|, \\ \\ \\ \\ b = 1, \\dots, B, \\ \\ k = 1, 2, 3.$$ </li>\n",
    "\n",
    "<li> Estimate 0.975th quantile of $(T_{n,k}^b)_{b=1}^B$ for k = 1, 2, 3, denoted $q_{0.975,k}^*$. </li>\n",
    "\n",
    "<li> Reject if $T_{n,k} = |\\frac{\\hat{\\beta}_k - \\beta_{k,0}}{\\sqrt{\\hat{V}_k/n}}| > q_{0.975,k}^*$. </li>\n",
    "\n",
    "</ol>\n",
    "\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33824ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc15aa2a-c22f-4542-b315-68640871d6b4",
   "metadata": {},
   "source": [
    "**3. Compare your results for the finite-sample approach (PS 3), the asymptotic approach (Eicker-White), and the bootstrap.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac3efc3-8ba2-4ca0-9d02-493aad35c05c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def789fe-ff47-4c07-91c9-fc966dc0ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for the timing of the code run time, please do not modify\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Total runtime: {end_time - start_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
